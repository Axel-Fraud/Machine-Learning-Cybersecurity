{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tZMBKeaUwLOk",
        "outputId": "577e6377-9be9-4615-bd67-f9c8e1babc8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.67.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "filename = 'data_password_only.csv'\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/DSC Projects/') #Change to your final project directory\n",
        "print(os.listdir())\n",
        "df = pd.read_csv(filename, header=None, dtype=str)\n",
        "df.columns = ['password']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KSZCi3Owl2C",
        "outputId": "a8353dc5-6ce7-4e3f-a8bb-7c01baced4d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "['NLP.ipynb', 'output_1.xlsx', 'output_1.xlsx_password_analysis.xlsx', 'password_statistics.csv', 'output_5.xlsx', 'output_3.xlsx', 'output_7.xlsx', 'profanity_en.csv', 'output_6.xlsx', 'output_4.xlsx', 'output_2.xlsx_password_analysis.xlsx', 'output_2.xlsx', 'data.csv', 'data_analysis.ipynb', 'Final Project Proposal.gdoc', 'data.gsheet', 'data_password_only.csv', 'passwords.txt', 'cached_lm_GPT2Tokenizer_32_passwords.txt.lock', 'cached_lm_GPT2Tokenizer_32_passwords.txt', 'password_generator', 'wandb', 'Recurrent Neural Network (RNN).ipynb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.head(100000)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWZpw5RmyYxe",
        "outputId": "562d287c-89c4-4960-9602-e651951aa2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "all_text = ''.join(df['password'].astype(str).tolist())\n",
        "chars = sorted(set(all_text))\n",
        "char_to_index = {c: i for i, c in enumerate(chars)}\n",
        "index_to_char = {i: c for i, c in enumerate(chars)}"
      ],
      "metadata": {
        "id": "Bymhoh3-we_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 10\n",
        "\n",
        "sequences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(all_text) - sequence_length):\n",
        "    sequences.append(all_text[i: i + sequence_length])\n",
        "    next_chars.append(all_text[i + sequence_length])\n",
        "\n",
        "# Vectorize sequences and next characters\n",
        "X = np.zeros((len(sequences), sequence_length, len(chars)), dtype=np.bool_)\n",
        "y = np.zeros((len(sequences), len(chars)), dtype=np.bool_)\n",
        "\n",
        "for i, seq in enumerate(sequences):\n",
        "    for t, char in enumerate(seq):\n",
        "        X[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_chars[i]]] = 1\n",
        "\n",
        "\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB9xebQuxsmC",
        "outputId": "6ec73a30-1c0c-4fe1-bd2c-5724840d13b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((998353, 10, 129), (998353, 129))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(128, input_shape=(sequence_length, len(chars))),\n",
        "    Dense(len(chars), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ahv9j96OwUZ_",
        "outputId": "ffe06a71-3789-4da3-c0c1-3016f2cf058d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=3, batch_size=128)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DN7eqUUysLs",
        "outputId": "7dc1ea76-84c0-41d0-c6a4-fa1582f6cf49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m7800/7800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 36ms/step - loss: 3.4044\n",
            "Epoch 2/3\n",
            "\u001b[1m7800/7800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 36ms/step - loss: 3.2286\n",
            "Epoch 3/3\n",
            "\u001b[1m7800/7800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 36ms/step - loss: 3.1907\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7946942c6ec0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, seed_text, length=50, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Generate text using the trained model.\n",
        "    - model: Trained LSTM model.\n",
        "    - seed_text: Initial string to start generating text.\n",
        "    - length: Number of characters to generate.\n",
        "    - temperature: Controls randomness in predictions. Lower values make the text more predictable.\n",
        "    \"\"\"\n",
        "    generated_text = seed_text\n",
        "    for _ in range(length):\n",
        "        # Vectorize the seed_text\n",
        "        sampled = np.zeros((1, len(seed_text), len(chars)))\n",
        "        for i, char in enumerate(seed_text):\n",
        "            sampled[0, i, char_to_index[char]] = 1\n",
        "\n",
        "        # Predict the next character\n",
        "        predictions = model.predict(sampled, verbose=0)[0]\n",
        "        predictions = np.asarray(predictions).astype('float64')\n",
        "\n",
        "        # Apply temperature to predictions to control randomness\n",
        "        predictions = np.log(predictions + 1e-8) / temperature\n",
        "        exp_preds = np.exp(predictions)\n",
        "        predictions = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        # Sample the next character based on adjusted probabilities\n",
        "        next_index = np.random.choice(range(len(chars)), p=predictions)\n",
        "        next_char = index_to_char[next_index]\n",
        "\n",
        "        # Append the next character to generated_text and update seed_text\n",
        "        generated_text += next_char\n",
        "        seed_text = seed_text[1:] + next_char  # Move window forward\n",
        "\n",
        "    return generated_text\n"
      ],
      "metadata": {
        "id": "zBo4eapd1waf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example seed text (choose a starting sequence)\n",
        "seed_text = \"119*02\"  # or select a common password pattern in your dataset\n",
        "\n",
        "# Generate new password-like text\n",
        "generated_password = generate_text(model, seed_text, length=10, temperature=0.5)\n",
        "print(\"Generated password:\", generated_password)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2pK5pk03KDl",
        "outputId": "402cd3bb-4b8e-4d33-c191-e2a1f2997a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated password: 119*0219699001ma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = 'models/recurrentNeuralNetwork.h5'\n",
        "\n",
        "# Save the model\n",
        "model.save(model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gKadL3F30PA",
        "outputId": "42be6446-5b4c-4996-e549-b2e26965836c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ]
}